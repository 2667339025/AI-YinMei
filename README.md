# **AI-YinMei**

- AI 虚拟主播 Vtuber 研发(N 卡版本)
- AI 名称：吟美
- 开发者：Winlone
- B 站频道：程序猿的退休生活
- B 站视频教程：https://www.bilibili.com/video/BV18b4y1V7Qm/
- Q 群：27831318
- 版本：1.7.6
- 详细笔记：<br>
  现在发现有道云笔记网页版本不能查看笔记图片，需要完整教案请进入 Q 群 27831318 获取 pdf 文档<br>
  https://note.youdao.com/s/1k0x7BLt<br>
- 吟美 pdf 完整说明文档：<br>
  百度网盘：https://pan.baidu.com/s/13tKUI2sFLyJAWrqzYkRaCw?pwd=1kz2<br>
  在百度网盘->人工智能->吟美说明文档->AI 虚拟主播 Vtuber 研发(N 卡版本)-v1.7.x.pdf<br>
- 吟美整合包下载地址：<br>
  视频教程：https://www.bilibili.com/video/BV1zD421H76q
  百度网盘：https://pan.baidu.com/s/13tKUI2sFLyJAWrqzYkRaCw?pwd=1kz2
  提取码：1kz2
  夸克：https://pan.quark.cn/s/ade5c2d30ae7
  提取码：ci9B
  整合包下载(4 个)：自媒体 -> 人工智能 -> Ai 吟美整合包
  整合包说明文档：自媒体 -> 人工智能 -> Ai 吟美整合包->Ai 吟美整合包.pdf
- 旧版吟美项目【因集成过多内置第三方项目，已废弃】：<br>https://github.com/worm128/AI-YinMei-backup

## **支持技术**

- 支持 fastgpt 知识库聊天对话
- 支持 LLM 大语言模型的一整套解决方案：[fastgpt] + [one-api] + [Xinference]
- 支持对接 bilibili 直播间弹幕回复和进入直播间欢迎语
- 支持微软 edge-tts 语音合成
- 支持 Bert-VITS2 语音合成
- 支持 GPT-SoVITS 语音合成
- 支持表情控制 Vtuber Studio
- 支持绘画 stable-diffusion-webui 输出 OBS 直播间
- 支持绘画图片鉴黄 public-NSFW-y-distinguish
- 支持搜索和搜图服务 duckduckgo（需要魔法上网）
- 支持搜图服务 baidu 搜图（不需要魔法上网）
- 支持 AI 回复聊天框【html 插件】
- 支持 AI 唱歌 Auto-Convert-Music
- 支持歌单【html 插件】
- 支持跳舞功能
- 支持表情视频播放
- 支持摸摸头动作
- 支持砸礼物动作
- 支持唱歌自动启动伴舞功能
- 聊天和唱歌自动循环摇摆动作
- 支持多场景切换、背景音乐切换、白天黑夜自动切换场景
- 支持开放性唱歌和绘画，让 AI 自动判断内容
- 支持流式聊天，提速 LLM 回复与语音合成
- 对接 bilibili 开放平台弹幕【稳定性高】

## **吟美直播间功能说明**

- 1、聊天功能：<br>
  设定了名字、性格、语气和嘲讽能力的 AI，能够与粉丝互怼，当然录入了老粉丝的信息记录，能够更好识别老粉丝的行为进行互怼。<br>
- 2、唱歌功能：<br>
  输入唱歌+歌曲名称，吟美会根据你输入的歌曲名称进行学习唱歌。当然，你可以输入类似“吟美给我推荐一首最好听的动漫歌曲”这些开放性的话题，让吟美给你智能选择歌曲进行演唱。<br>
- 3、绘画功能：<br>
  输入画画+图画标题，吟美会根据你输入的绘画提示词进行实时绘画。当然，你可以输入类似“吟美给我画一幅最丑的小龟蛋”这些开放性的话题，让吟美给你智能输出绘画提示词进行画画。<br>
- 4、跳舞功能：<br>
  输入跳舞+舞蹈名称，舞蹈如下：<br>
  书记舞、科目三、女团舞、社会摇<br>
  呱呱舞、马保国、二次元、涩涩<br>
  蔡徐坤、江南 style、Chipi、吟美<br>
  直接输入“跳舞”两个字是随机跳舞<br>
- 5、表情功能：<br>
  输入#号+表情名称, #rnd 是随机表情，表情自己猜，例如，“哭、笑、吐舌头”之类<br>
- 6、场景切换功能：<br>
  输入切换+场景名称： 粉色房间、神社、海岸花坊、花房、清晨房间，系统智能判定时间进行早晚场景切换<br>
- 7、换装功能：<br>
  输入换装+衣服名称：便衣、爱的翅膀、青春猫娘、眼镜猫娘<br>
- 8、搜图功能：<br>
  输入搜图+关键字<br>
- 9、搜索资讯功能：<br>
  输入搜索+关键字<br>

- 智能辅助：<br>
  1、歌单列表显示<br>
  2、Ai 回复文字框显示<br>
  3、Ai 动作状态提示<br>
  4、智能识别唱歌和绘画<br>
  5、说话、唱歌循环随机摇摆动作<br>
  6、随着心情值增加或者当前的聊天关键字，智能判断输出日语<br>
  7、绘画提示词对接 C 站，丰富绘画内容<br>
  8、智能判断是否需要唱歌、画画<br>
  9、根据关键字进行场景切换<br>

### 应用模块

- Ai-YinMei：Ai 吟美核心<br>
- stable-diffusion-webui：绘画模块<br>
- public-NSFW-y-distinguish：鉴黄模块<br>
- gpt-SoVITS：语音合成模块<br>
- Auto-Convert-Music：唱歌模块<br>
- fastgpt + one-api + Xinference：聊天模块<br>

### 软件下载

- 在百度网盘：https://pan.baidu.com/s/1wB1aNTpN5X2WSPCq3GADJw?pwd=1kz2
- 语音播放器 mpv：语音播放、音乐播放使用<br>
  在百度网盘->人工智能->软件->mpv.exe<br>
  注意：项目需要在根目录放两个播放器，分别是：mpv.exe【播放语音】、song.exe【播放音乐】<br>
- 虚拟声卡：虚拟人物口型输出音频<br>
  在百度网盘->人工智能->软件->虚拟声卡 Virtual Audio Cable v4.10 破解版<br>
- ffmpeg：音频解码器，用于语音合成<br>
  在百度网盘->人工智能->软件->ffmpeg<br>
- mongodb 连接工具-NoSQLBooster for MongoDB<br>
  人工智能->软件->nosqlbooster4mongo-8.1.7.exe<br>
- fastgpt 的 docker-compose 配置<br>
  人工智能->软件->docker 知识库<br>
- 整合包路径<br>
  百度网盘：https://pan.baidu.com/s/1wB1aNTpN5X2WSPCq3GADJw?pwd=1kz2<br>
  提取码：1kz2<br>
  夸克：https://pan.quark.cn/s/ade5c2d30ae7<br>
  提取码：ci9B<br>

### 运行环境

- Python 3.11.6

### 启动方式

#### 1、(必选)启动应用层，在根目录

```bash
#进入虚拟环境
& 盘符:路径/pylib/aivenv/Scripts/Activate.ps1
#安装py包
pip install -r requirements.txt
#启动对接b站直播程序
#一：1.b站直播间 2.api web
#二：1.fastgpt   1.text-generation-webui
#三：输入你的B站直播间编号
python bilibili-live-api.py
```

#### 修改内容须知：

人工智能名称：Ai_Name="吟美"
直播间配置：yml 配置-room_id
B 站直播间鉴权：yml 配置-sessdata、ACCESS_KEY_ID、ACCESS_KEY_SECRET、APP_ID、ROOM_OWNER_AUTH_CODE<br>
sessdata：直播间会话值<br>
ACCESS_KEY_ID、ACCESS_KEY_SECRET：在开放平台申请的开发者密钥<br>
APP_ID：在开放平台创建的项目 ID<br>
ROOM_OWNER_AUTH_CODE：B 站身份码<br>
Vtuber Studio 表情 websocket 服务： <br>
ws = websocket.WebSocketApp("ws://127.0.0.1:8001",on_open = on_open)<br>
以下是表情鉴权，详细看文档【十三、Vtuber 表情控制-获取令牌和授权】：<br>
vtuber_pluginName="自定义插件名称"<br>
vtuber_pluginDeveloper="winlone"<br>
vtuber_authenticationToken="这个令牌从获取令牌接口获取"<br>
鉴黄服务：nsfw_server="192.168.2.198:1801"<br>
唱歌服务 Auto-Convert-Music 地址：singUrl = "192.168.2.58:1717"<br>
绘画服务 stable-diffusion-webui 地址：drawUrl = "192.168.2.58:7860"<br>
聊天服务 text-generation-webui 地址：tgwUrl = "192.168.2.58:5000"<br>
聊天服务 fastgpt 知识库地址：fastgpt_url = "192.168.2.198:3000"<br>
fastgpt 令牌：fastgpt_authorization="Bearer fastgpt-GNtIO9ApmbiFdC0R5IVkoXN5TGdGyiURh7bJ8i8CTyVINpU3GjN4Wr"<br>
搜索服务代理：duckduckgo_proxies="socks5://127.0.0.1:10806"<br>
搜图服务代理：proxies = {"http": "socks5://127.0.0.1:10806", "https": "socks5://127.0.0.1:10806"}<br>
流式分割字符：split_flag=",|，|。|!|！|?|？|\n"
流式分割字符数量：split_num = 4

#### 2-1、(可选)启动 LLM 聊天服务 【fastgpt】+【one-api】+【Xinference】<br>

fastgpt：https://github.com/labring/FastGPT<br>
one-api：https://github.com/songquanpeng/one-api<br>
Xinference：https://github.com/xorbitsai/inference<br>
启动：使用 window WSL 的 docker 启动，启动流程看教程文档第 23 点<br>

#### 2-2、(可选)启动 LLM 聊天服务 text-generation-webui<br>

项目 github：https://github.com/oobabooga/text-generation-webui<br>

```bash
#进入虚拟环境
& 盘符:py虚拟空间路径/Scripts/Activate.ps1
#安装py包
pip install -r requirements.txt
#启动text-generation-webui程序，start.bat是我自定义的window启动脚本
./start.bat
```

window 的 bat 启动命令：

```bash
python server.py --trust-remote-code --listen-host 0.0.0.0 --listen-port 7866 --listen --api --api-port 5000 --model chatglm2-6b --load-in-8bit --bf16
```

API 访问：http://127.0.0.1:5000/

#### 3、(必选)语音合成-Ai 发声<br>

项目地址：https://github.com/fishaudio/Bert-VITS2<br>
启动：使用 Bert-VITS2-clap-novq-ui 里面的 start.bat 启动<br>
定制页面：hiyoriUI.py 包含中英日混合语音合成方法，需要放到对应项目，不一定兼容<br>
效果：Ai 与用户的语音互动，包括：聊天、绘画提示、唱歌提示、跳舞提示等

#### 4、(可选)启动绘画服务 stable-diffusion-webui<br>

项目地址：https://github.com/AUTOMATIC1111/stable-diffusion-webui<br>

```bash
#进入虚拟环境
& 盘符:py虚拟空间路径/Scripts/Activate.ps1
#安装py包
pip install -r requirements.txt
#配置api服务webui-user.bat
@echo off
set PYTHON=.\pydraw\Scripts\python.exe
set GIT=
set VENV_DIR=.\pydraw\
set COMMANDLINE_ARGS=--api
call webui.bat
#启动text-generation-webui程序，start.bat是我自定义的window启动脚本
./webui-user.bat
```

效果：输入“画画 xxx”，触发 Ai 使用 stable-diffusion 进行绘图<br>

#### 5、(可选)启动绘画鉴黄服务 public-NSFW-y-distinguish<br>

项目地址：https://github.com/fd-freedom/public-NSFW-y-distinguish<br>

```bash
运行环境（必要）：Python 3.6.13
pip install -r requirements.txt
# 此文件为本人特制
py nsfw_web.py
```

#### 6、(可选)启动唱歌服务 Auto-Convert-Music<br>

原创开发者：木白 Mu_Bai、宫园薰ヾ(≧∪≦\*)ノ〃<br>
项目地址：https://github.com/MuBai-He/Auto-Convert-Music<br>
启动：使用 Auto-Convert-Music 里面的 start.bat 启动<br>
效果：输入“唱歌 歌曲名称”，触发 Ai 从歌库学习唱歌<br>

#### 7、(必选)皮肤启动，安装 steam，安装 VTube Studio<br>

这个自行下载 steam 平台，在平台里面有一个 VTube Studio 软件，它就是启动 live2D 的虚拟主播皮肤<br>

#### 8、(必选)虚拟声卡驱动<br>

安装虚拟声卡：虚拟声卡驱动（Virtual Audio Cable）4.66 官方版<br>
效果：Ai 主播的发声来源

#### 9、(可选)AI 回复框【HTML 插件】<br>

把项目文件：ai-yinmei\html\chatui.html 放入 OBS 浏览器插件展示<br>
效果：Ai 的回复内容会在回复插件显示<br>

#### 10、(可选)歌单显示【HTML 插件】<br>

把项目文件：ai-yinmei\html\songlist.html 放入 OBS 浏览器插件展示<br>
效果：用户点歌的歌单会在上面以列表形式显示：<br>
'xxx 用户'点播《歌曲名称》[正在播放]<br>
'xxx 用户 2'点播《歌曲名称》<br>

#### 11、(可选)时间显示【HTML 插件】<br>

把项目文件：ai-yinmei\html\time.html 放入 OBS 浏览器插件展示<br>

此外，需要在 text-generation-webui/models 路径放入 LLM 模型，我这里放的是 chatgml2 的模型，大家可以任意选择底层 LLM 模型，例如，千问、百川、chatglm、llama 等<br>
更多详细技术细节，请看技术文档：https://note.youdao.com/s/1k0x7BLt<br>

#### 12、(可选)跳舞能力<br>

跳舞视频的存放地址【支持子文件夹存放】： dance_path = 'J:\\ai\\跳舞视频\\横屏'<br>
效果：输入跳舞，立即进行跳舞视频随机抽取播放；输入\停止跳舞，可以立即停止跳舞<br>

#### 13、(可选)弹出视频表情<br>

表情视频的存放地址【支持子文件夹存放】： emote_path = 'H:\\人工智能\\ai\\跳舞视频\\表情'<br>
效果：输入#rnd 或者 #表情视频文件名，立即进行表情视频播放，#rnd 为随机播放表情视频<br>
表情视频的名称展示【支持子文件夹存放】： emote_font = 'H:\\人工智能\\ai\\跳舞视频\\表情\\表情符号'<br>
效果：表情名称会显示在 obs 的字体控件，提示用户可以输入这些表情名称<br>

### 目录说明

- text-generation-webui【第三方工具】：<br>
  LLM 聚合接口，可以放置 chatglm 等大语言模型，然后进行参数配置后，再输入角色卡进行角色扮演聊天<br>
  https://github.com/oobabooga/text-generation-webui<br>
- LLaMA-Factory【AI 训练】：<br>
  AI 聚合训练工具，可以界面化配置训练参数，可视化 ai 训练，相当强大<br>
  https://github.com/hiyouga/LLaMA-Factory<br>
- ChatGLM、ChatGLM2、ChatGLM3【语言模型】：<br>
  放置的是清华大学研发的自然语言模型，可以自行添加如：百川、千问、LLAMA 等其他大语言模型<br>
- SillyTavern【第三方工具】：<br>
  酒馆，强大的 AI 角色扮演，但是该项目没有公开接口调用，而且 TTS 语言合成很缓慢，暂未集成使用<br>
  https://github.com/SillyTavern/SillyTavern<br>
- output【输出路径】：<br>
  输出的文本 txt、语音 mp3 文件都在这里<br>
- ChatGLM2\ptuning【AI 训练】：<br>
  ChatGLM 官方训练例子<br>
- ChatGLM2\ptuning\zero_nlp【AI 训练】：<br>
  ai 的 lora 训练模式<br>

### 特别鸣谢

- 唱歌变声：Auto-Convert-Music 开发者：木白 Mu_Bai、宫园薰ヾ(≧∪≦\*)ノ〃<br>
  项目地址：https://github.com/MuBai-He/Auto-Convert-Music<br>
- GPT-SoVITS：花儿不哭大佬开发的 TTS 语音合成<br>
  https://github.com/RVC-Boss/GPT-SoVITS<br>
- Bert-VITS2：TTS 语音合成，合成速度超快<br>
  https://github.com/fishaudio/Bert-VITS2<br>
- 知识库：fastgpt<br>
  项目地址：https://github.com/labring/FastGPT<br>
- 大语言模型框架：one-api + Xinference<br>
  项目地址：https://github.com/songquanpeng/one-api<br>
  项目地址：https://github.com/xorbitsai/inference<br>
- LLM 模型：ChatGLM<br>
  https://github.com/THUDM/ChatGLM2-6B<br>
- 聚合 LLM 调用模型：text-generation-webui<br>
  https://github.com/oobabooga/text-generation-webui<br>
- AI 虚拟主播模型：B 站的·领航员未鸟·<br>
  https://github.com/AliceNavigator/AI-Vtuber-chatglm<br>
- AI 训练模型：LLaMA-Factory<br>
  https://github.com/hiyouga/LLaMA-Factory<br>
- MPV 播放器：MPV<br>
  https://github.com/mpv-player/mpv<br>
- 其他：<br>
  Lora 训练：https://github.com/yuanzhoulvpi2017/zero_nlp<br>
  ChatGLM 训练：https://github.com/hiyouga/ChatGLM-Efficient-Tuning<br>
  SillyTavern 酒馆：https://github.com/SillyTavern/SillyTavern<br>
  LoRA 中文训练：https://github.com/super-wuliao/LoRA-ChatGLM-Chinese-Alpaca<br>
  数据集-训练语料：https://github.com/codemayq/chinese-chatbot-corpus<br>

### 更多关注

- 讨论 Q 群：27831318<br>
